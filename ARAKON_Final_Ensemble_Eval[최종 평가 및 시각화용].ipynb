{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# [0] í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ (sys í¬í•¨, ì—ëŸ¬ ë°©ì§€)\n",
    "# ======================================================================================\n",
    "# !pip install ensemble-boxes  # ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ì£¼ì„ í•´ì œ í›„ ì‹¤í–‰\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn import tasks, modules\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "\n",
    "print(f\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ (Python {sys.version.split()[0]})\")\n",
    "\n",
    "# ======================================================================================\n",
    "# [1] CBAM í´ë˜ìŠ¤ ì •ì˜ (ëª¨ë¸ ë¡œë“œë¥¼ ìœ„í•œ í•„ìˆ˜ ë¶€í’ˆ)\n",
    "# ======================================================================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM_Universal(nn.Module):\n",
    "    def __init__(self, *args, **kwargs): \n",
    "        super(CBAM_Universal, self).__init__()\n",
    "        c1 = args[0]\n",
    "        k = 7 \n",
    "        self.channel_attention = ChannelAttention(c1)\n",
    "        self.spatial_attention = SpatialAttention(k)\n",
    "    def forward(self, x):\n",
    "        out = self.channel_attention(x) * x\n",
    "        out = self.spatial_attention(out) * out\n",
    "        return out\n",
    "\n",
    "# ì‹œìŠ¤í…œ ê°•ì œ ë“±ë¡ (Monkey Patching)\n",
    "target_name = 'CBAM_Universal'\n",
    "for module_list in [tasks, modules]:\n",
    "    setattr(module_list, target_name, CBAM_Universal)\n",
    "if 'ultralytics.nn.modules' in sys.modules:\n",
    "    setattr(sys.modules['ultralytics.nn.modules'], target_name, CBAM_Universal)\n",
    "print(f\"âœ… [ì‹œìŠ¤í…œ] CBAM ëª¨ë“ˆ ë“±ë¡ ì™„ë£Œ.\")\n",
    "\n",
    "# ======================================================================================\n",
    "# [2] ëª¨ë¸ ë¡œë“œ (ê²½ë¡œ í™•ì¸ í•„ìˆ˜!)\n",
    "# ======================================================================================\n",
    "# 1ë²ˆ ëª¨ë¸: 640 ë² ì´ìŠ¤\n",
    "path_640 = \"runs/detect/tank_yolo_cbam_640_final/weights/best.pt\"\n",
    "# 2ë²ˆ ëª¨ë¸: 800 Class Tuning (ê°€ì¥ ì„±ëŠ¥ ì¢‹ì•˜ë˜ ê²ƒ)\n",
    "path_800 = \"runs/detect/tank_yolo_cbam_cls_tuning/weights/best.pt\"\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì„¤ì •\n",
    "data_yaml_path = \"C:/Users/hyun8/Desktop/Arakon/detection-base-6/data.yaml\"\n",
    "test_image_dir = \"C:/Users/hyun8/Desktop/Arakon/detection-base-6/test/images\"\n",
    "save_dir = \"runs/detect/ensemble_final_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "class_names = ['APC', 'Tank', 'person'] # í´ë˜ìŠ¤ ìˆœì„œ ì£¼ì˜ (0, 1, 2)\n",
    "\n",
    "model_640 = None\n",
    "model_800 = None\n",
    "\n",
    "try:\n",
    "    if os.path.exists(path_640):\n",
    "        model_640 = YOLO(path_640)\n",
    "        print(\"âœ… 640 ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "    \n",
    "    if os.path.exists(path_800):\n",
    "        model_800 = YOLO(path_800)\n",
    "        print(\"âœ… 800 ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "    \n",
    "    if model_640 is None or model_800 is None:\n",
    "        print(\"ğŸš¨ ëª¨ë¸ íŒŒì¼ì´ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ì•™ìƒë¸”ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ======================================================================================\n",
    "# [3] ì•™ìƒë¸” ì‹¤í–‰ ë° ì‹œê°í™” (ì´ë¯¸ì§€ ì €ì¥ìš©)\n",
    "# ======================================================================================\n",
    "def run_wbf(img_path, weights=[1, 2]): # 800 ëª¨ë¸(ë’¤ìª½)ì— 2ë°° ê°€ì¤‘ì¹˜\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None: return None, None, None, None\n",
    "    h, w, _ = image.shape\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # ê° ëª¨ë¸ ì˜ˆì¸¡ (TTA ì ìš©)\n",
    "    preds_640 = model_640.predict(image_rgb, imgsz=640, conf=0.2, verbose=False, augment=True)\n",
    "    preds_800 = model_800.predict(image_rgb, imgsz=800, conf=0.2, verbose=False, augment=True)\n",
    "\n",
    "    boxes_list, scores_list, labels_list = [], [], []\n",
    "\n",
    "    # ê²°ê³¼ íŒŒì‹±\n",
    "    for preds in [preds_640, preds_800]:\n",
    "        for result in preds:\n",
    "            boxes_list.append(result.boxes.xyxyn.cpu().numpy())\n",
    "            scores_list.append(result.boxes.conf.cpu().numpy())\n",
    "            labels_list.append(result.boxes.cls.cpu().numpy())\n",
    "\n",
    "    # WBF ì ìš©\n",
    "    boxes, scores, labels = weighted_boxes_fusion(\n",
    "        boxes_list, scores_list, labels_list, \n",
    "        weights=weights, iou_thr=0.6, skip_box_thr=0.01\n",
    "    )\n",
    "    return boxes, scores, labels, image_rgb\n",
    "\n",
    "# 5ì¥ ìƒ˜í”Œë§í•˜ì—¬ ì‹¤í–‰\n",
    "if model_640 and model_800:\n",
    "    image_files = [os.path.join(test_image_dir, f) for f in os.listdir(test_image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    sample_images = random.sample(image_files, min(5, len(image_files)))\n",
    "    \n",
    "    print(f\"\\nğŸ“¸ {len(sample_images)}ì¥ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ ì•™ìƒë¸” ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        boxes, scores, labels, image = run_wbf(img_path, weights=[1, 2])\n",
    "        if boxes is None: continue\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        h, w, _ = image.shape\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            x1, y1, x2, y2 = int(box[0]*w), int(box[1]*h), int(box[2]*w), int(box[3]*h)\n",
    "            color = (0, 255, 0) if int(label) == 1 else (255, 0, 0) \n",
    "            \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            label_text = f\"{class_names[int(label)]} {score:.2f}\"\n",
    "            cv2.putText(image, label_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Ensemble Result - {os.path.basename(img_path)}\")\n",
    "        plt.show()\n",
    "        \n",
    "        save_path = os.path.join(save_dir, f\"ens_{os.path.basename(img_path)}\")\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"ğŸ‰ ì•™ìƒë¸” ì‹œê°í™” ì™„ë£Œ! ê²°ê³¼: '{save_dir}'\")\n",
    "\n",
    "# ======================================================================================\n",
    "# [4] ìµœì¢… ì„±ëŠ¥ í™•ì¸ (mAP ì¸¡ì •) - Best Model + TTA\n",
    "# ======================================================================================\n",
    "# ì£¼ì˜: ì»¤ìŠ¤í…€ ì•™ìƒë¸”ì˜ mAPë¥¼ ì§ì ‘ ì¬ë ¤ë©´ ë³µì¡í•œ ì½”ë“œê°€ í•„ìš”í•˜ë¯€ë¡œ, \n",
    "# ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ '800 ëª¨ë¸'ì— 'TTA(Test Time Augmentation)'ë¥¼ ì ìš©í•œ ì ìˆ˜ë¥¼ \n",
    "# ìµœì¢… ì„±ì í‘œë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•˜ê³  ì ìˆ˜ê°€ ì˜ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "\n",
    "print(\"\\nğŸ“Š [ìµœì¢… ì„±ì í‘œ] Best Model + TTA(ì¦ê°• ì¶”ë¡ ) ì„±ëŠ¥ ì¸¡ì • ì¤‘...\")\n",
    "\n",
    "if model_800:\n",
    "    # 800 ëª¨ë¸ì— TTA(augment=True)ë¥¼ ì¼œì„œ ê²€ì¦(Validation) ìˆ˜í–‰\n",
    "    metrics = model_800.val(\n",
    "        data=data_yaml_path, \n",
    "        split='test',   # test ì…‹ìœ¼ë¡œ í‰ê°€\n",
    "        imgsz=800, \n",
    "        batch=4,        # ë©”ëª¨ë¦¬ ì•ˆì „\n",
    "        augment=True,   # [í•µì‹¬] TTA ì¼œê¸° (ì ìˆ˜ ìƒìŠ¹ íš¨ê³¼)\n",
    "        workers=0       # ìœˆë„ìš° ì•ˆì „\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"ğŸ† ìµœì¢… mAP@50    : {metrics.box.map50:.4f}\")\n",
    "    print(f\"ğŸ† ìµœì¢… mAP@50-95 : {metrics.box.map:.4f}\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"ğŸ’¡ ì´ ì ìˆ˜ë¥¼ ë³´ê³ ì„œì˜ 'ìµœì¢… ì„±ëŠ¥'ìœ¼ë¡œ ê¸°ì¬í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"ğŸš¨ í‰ê°€í•  ëª¨ë¸(800)ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
