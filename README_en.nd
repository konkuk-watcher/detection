
---

### ðŸ‡ºðŸ‡¸ **README_en.md**

```markdown
# ðŸŒ CNN â†” ViT Hybrid Bidirectional Architecture (Option 1)

> **Type:** Battlefield AI Research / Simulation Based  
> **Framework:** PyTorch  
> **Structure:** Local â†’ Global â†’ Local (Bidirectional Feedback)  
> **Goal:** Fuse CNNâ€™s local perception and ViTâ€™s global reasoning for robust scene understanding.

---

## 1ï¸âƒ£ Background

Modern battlefield AI requires lightweight but high-precision perception models on edge devices (soldier nodes and drones).  
CNNs excel at local pattern recognition but lack contextual awareness; ViTs capture global relations but lose spatial detail.  
This project bridges them through a **bidirectional Local-Global fusion** design.

---

## 2ï¸âƒ£ Design Principles

- **Local Perception:** CNN extracts edges and fine textures.  
- **Global Reasoning:** ViT models relationships among patches via self-attention.  
- **Bidirectional Fusion:** CNN features feed into ViT; ViT tokens feed back into CNN for spatial reconstruction.  

---

## 3ï¸âƒ£ Architecture

```text
Input Image (224Ã—224)
   â†“
CNN Encoder (Local Feature Extraction)
   â†“
Flatten + Patch Embedding
   â†“
ViT Encoder (Global Token Reasoning)
   â†“
CNN Decoder (Spatial Reconstruction)
   â†“
Detection Head (e.g., YOLO)


## 4ï¸âƒ£ Core Workflow

```
from models import CNNEncoder, ViTEncoder, CNNDecoder
from yolo_head import DetectionHead

x = load_image(...)
f = CNNEncoder(x)
t = ViTEncoder(f)
recon = CNNDecoder(t)
out = DetectionHead(recon)
```

## Requirements

Python >= 3.10
torch >= 2.2
torchvision >= 0.17
timm >= 1.0
opencv-python
matplotlib
numpy

## Usage

python train.py --model hybrid_bidir --dataset arma3 --epochs 50
python infer.py --input sample.jpg --weights checkpoints/hybrid_best.pt
