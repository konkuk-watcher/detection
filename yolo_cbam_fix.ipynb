{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ebb633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.235)\n",
      "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (12.0.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu128)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (7.1.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.36.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
      "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.0 in /usr/local/lib/python3.12/dist-packages (from polars>=0.20.0->ultralytics) (1.36.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install ultralytics roboflow pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80650053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn import tasks, modules\n",
    "from roboflow import Roboflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e5f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [ì¤€ë¹„ ì™„ë£Œ] ëª¨ë“ˆ 'CBAM_Universal' ì‹œìŠ¤í…œ ë“±ë¡ë¨.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# 1. CBAM ëª¨ë“ˆ ì •ì˜\n",
    "# ======================================================================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "class CBAM_Universal(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLO ì»¤ìŠ¤í…€ ëª¨ë“ˆë¡œ ì“°ê¸° ìœ„í•œ Universal CBAM.\n",
    "    YAMLì—ì„œ [ 'CBAM_Universal', [channels] ] í˜•íƒœë¡œ í˜¸ì¶œë¨.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CBAM_Universal, self).__init__()\n",
    "        c1 = args[0]  # in_channels\n",
    "        k = 7\n",
    "        print(f\"âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: {c1}\")\n",
    "        self.channel_attention = ChannelAttention(c1)\n",
    "        self.spatial_attention = SpatialAttention(k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.channel_attention(x) * x\n",
    "        out = self.spatial_attention(out) * out\n",
    "        return out\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# 2. Ultralytics ë‚´ë¶€ì— ëª¨ë“ˆ ë“±ë¡\n",
    "# ======================================================================================\n",
    "target_name = 'CBAM_Universal'\n",
    "\n",
    "for module_list in [tasks, modules]:\n",
    "    setattr(module_list, target_name, CBAM_Universal)\n",
    "\n",
    "# ì´ë¯¸ importëœ ëª¨ë“ˆ ìºì‹œì— ì§ì ‘ ì£¼ì… (ì•ˆì „ë¹µ)\n",
    "if 'ultralytics.nn.modules' in sys.modules:\n",
    "    setattr(sys.modules['ultralytics.nn.modules'], target_name, CBAM_Universal)\n",
    "\n",
    "print(f\"âœ… [ì¤€ë¹„ ì™„ë£Œ] ëª¨ë“ˆ '{target_name}' ì‹œìŠ¤í…œ ë“±ë¡ë¨.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9515449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [ì¤€ë¹„ ì™„ë£Œ] YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: yolov8m_cbam_real_final.yaml\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# 3. YOLOv8m + CBAM ì»¤ìŠ¤í…€ YAML ìƒì„±\n",
    "#    - ì±„ë„: 192 / 384 / 576 (ì˜¤ë¥˜ ë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶˜ ê°’)\n",
    "# ======================================================================================\n",
    "\n",
    "cbam_yaml = {\n",
    "    'nc': 3,  # í´ë˜ìŠ¤ ìˆ˜ (í•„ìš”í•˜ë©´ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë¨)\n",
    "    'scales': {'m': [0.67, 0.75, 768]},\n",
    "    'backbone': [\n",
    "        # [from, number, module, args]\n",
    "        [-1, 1, 'Conv', [64, 3, 2]],\n",
    "        [-1, 1, 'Conv', [128, 3, 2]],\n",
    "        [-1, 3, 'C2f', [128, True]],\n",
    "\n",
    "        [-1, 1, 'Conv', [256, 3, 2]],\n",
    "        [-1, 6, 'C2f', [256, True]],\n",
    "\n",
    "        # CBAM 1 (ì±„ë„ 192)\n",
    "        [-1, 1, target_name, [192]],  # idx 5\n",
    "\n",
    "        [-1, 1, 'Conv', [512, 3, 2]],\n",
    "        [-1, 6, 'C2f', [512, True]],\n",
    "\n",
    "        # CBAM 2 (ì±„ë„ 384)\n",
    "        [-1, 1, target_name, [384]],  # idx 8\n",
    "\n",
    "        [-1, 1, 'Conv', [1024, 3, 2]],\n",
    "        [-1, 3, 'C2f', [1024, True]],\n",
    "\n",
    "        # CBAM 3 (ì±„ë„ 576)\n",
    "        [-1, 1, target_name, [576]],  # idx 11\n",
    "\n",
    "        [-1, 1, 'SPPF', [1024, 5]]    # idx 12\n",
    "    ],\n",
    "    'head': [\n",
    "        # P5 â†’ P4\n",
    "        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n",
    "        [[-1, 8], 1, 'Concat', [1]],\n",
    "        [-1, 3, 'C2f', [512]],\n",
    "\n",
    "        # P4 â†’ P3\n",
    "        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n",
    "        [[-1, 5], 1, 'Concat', [1]],\n",
    "        [-1, 3, 'C2f', [256]],\n",
    "\n",
    "        # P3 â†’ P4\n",
    "        [-1, 1, 'Conv', [256, 3, 2]],\n",
    "        [[-1, 15], 1, 'Concat', [1]],\n",
    "        [-1, 3, 'C2f', [512]],\n",
    "\n",
    "        # P4 â†’ P5\n",
    "        [-1, 1, 'Conv', [512, 3, 2]],\n",
    "        [[-1, 11], 1, 'Concat', [1]],\n",
    "        [-1, 3, 'C2f', [1024]],\n",
    "\n",
    "        # Detect\n",
    "        [[18, 21, 24], 1, 'Detect', ['nc']]\n",
    "    ]\n",
    "}\n",
    "\n",
    "yaml_name = 'yolov8m_cbam_real_final.yaml'\n",
    "with open(yaml_name, 'w') as f:\n",
    "    yaml.dump(cbam_yaml, f, sort_keys=False)\n",
    "\n",
    "print(f\"âœ… [ì¤€ë¹„ ì™„ë£Œ] YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290947c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "âœ… Roboflow ë°ì´í„°ì…‹ ìœ„ì¹˜: /workspace/detection-base-6\n",
      "âœ… data.yaml ê²½ë¡œ: /workspace/detection-base-6/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# 4. Roboflow ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "# ======================================================================================\n",
    "\n",
    "RF_API_KEY = \"HG9M6YJZpcCUgAQaKO9v\"  # ë„ˆê°€ ì“°ë˜ í‚¤ ê·¸ëŒ€ë¡œ\n",
    "WORKSPACE = \"arakon\"\n",
    "PROJECT = \"detection-base-hqaeg\"\n",
    "VERSION = 6\n",
    "FORMAT = \"yolov8\"\n",
    "\n",
    "rf = Roboflow(api_key=RF_API_KEY)\n",
    "project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "version = project.version(VERSION)\n",
    "dataset = version.download(FORMAT)\n",
    "\n",
    "data_path = f\"{dataset.location}/data.yaml\"\n",
    "print(\"âœ… Roboflow ë°ì´í„°ì…‹ ìœ„ì¹˜:\", dataset.location)\n",
    "print(\"âœ… data.yaml ê²½ë¡œ:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ceceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 5. YOLO + CBAM í•™ìŠµ ìœ í‹¸ í•¨ìˆ˜\n",
    "# ======================================================================================\n",
    "\n",
    "def train_stage(\n",
    "    yaml_path: str,\n",
    "    data_yaml: str,\n",
    "    imgsz: int,\n",
    "    batch: int,\n",
    "    epochs: int,\n",
    "    patience: int,\n",
    "    run_name: str,\n",
    "    device: int = 0,\n",
    "    workers: int = 4,\n",
    "    cache = False,\n",
    "    lr0: float = 0.001,\n",
    "    lrf: float = 0.01,\n",
    "    cos_lr: bool = True,\n",
    "    optimizer: str = \"AdamW\",\n",
    "    mosaic: float = 1.0,\n",
    "    mixup: float = 0.1,\n",
    "    close_mosaic: int = 10,\n",
    "    pretrained_ckpt: str = \"yolov8m.pt\",\n",
    "):\n",
    "    \"\"\"\n",
    "    YOLOv8 + CBAM í•œ ìŠ¤í…Œì´ì§€ í•™ìŠµ í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘ | imgsz={imgsz}, batch={batch}, epochs={epochs}, cache={cache}, run={run_name}\")\n",
    "\n",
    "    model = YOLO(yaml_path).load(pretrained_ckpt)\n",
    "\n",
    "    model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        optimizer=optimizer,\n",
    "        lr0=lr0,\n",
    "        lrf=lrf,\n",
    "        cos_lr=cos_lr,\n",
    "        mosaic=mosaic,\n",
    "        mixup=mixup,\n",
    "        close_mosaic=close_mosaic,\n",
    "        cache=cache,\n",
    "        device=device,\n",
    "        workers=workers,\n",
    "        name=run_name,\n",
    "        exist_ok=True,\n",
    "        deterministic=False\n",
    "    )\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"âœ… í•™ìŠµ ì¢…ë£Œ | {run_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd29d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ | imgsz=640, batch=16, epochs=60, cache=True, run=tank_yolo_cbam_640_final\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      "Transferred 135/484 items from pretrained weights\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45498MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/detection-base-6/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m_cbam_real_final.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=tank_yolo_cbam_640_final, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8m.pt, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspace/runs/detect/tank_yolo_cbam_640_final, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "  5                  -1  1      4706  CBAM_Universal                               [192]                         \n",
      "  6                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  7                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "  8                  -1  1     18530  CBAM_Universal                               [384]                         \n",
      "  9                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      " 10                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      " 11                  -1  1     41570  CBAM_Universal                               [576]                         \n",
      " 12                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 5]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 19                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 22                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 23            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 25        [18, 21, 24]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
      "YOLOv8m_cbam_real_final summary: 193 layers, 25,922,863 parameters, 25,922,847 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 484/484 items from pretrained weights\n",
      "Freezing layer 'model.25.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 19.6Â±4.8 MB/s, size: 61.1 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/detection-base-6/train/labels.cache... 1384 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1384/1384 90.7Mit/s 0.0s\n",
      "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.6GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1384/1384 359.8it/s 3.8s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 25.3Â±9.5 MB/s, size: 75.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/detection-base-6/valid/labels.cache... 132 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 132/132 2.3Mit/s 0.0s\n",
      "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 132/132 322.5it/s 0.4s\n",
      "Plotting labels to /workspace/runs/detect/tank_yolo_cbam_640_final/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 93 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/runs/detect/tank_yolo_cbam_640_final\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1/60       7.7G      3.234       3.42      3.523         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 4.9it/s 17.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 6.6it/s 0.8s\n",
      "                   all        132        271      0.672     0.0992    0.00433    0.00132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2/60       7.7G      2.543      2.753      2.978         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.2it/s 16.6s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 5.1it/s 1.0s\n",
      "                   all        132        271     0.0232      0.242     0.0226    0.00685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       3/60       7.7G      2.174      2.442      2.637         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.3s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 6.9it/s 0.7s\n",
      "                   all        132        271      0.156      0.328      0.186     0.0813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       4/60       7.7G      2.047       2.28      2.481         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 6.1it/s 0.8s\n",
      "                   all        132        271      0.304      0.434      0.279      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5/60      8.18G      1.911      2.169       2.33         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.333      0.524      0.354      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6/60      8.18G       1.82      2.072      2.234         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.479      0.357      0.373      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       7/60      8.18G      1.778      2.036      2.193         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.331        0.6      0.447       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8/60      8.18G      1.755      2.015      2.158         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.346      0.563       0.45       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       9/60      8.18G       1.68      1.896      2.071         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.453      0.578      0.474      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10/60       8.2G      1.651      1.874      2.051         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.519      0.616      0.503      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11/60       8.2G      1.587      1.802          2         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.524      0.542      0.521      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12/60       8.2G      1.564       1.75      1.985         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.596      0.638      0.603       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13/60       8.2G      1.554      1.698      1.946         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271       0.56      0.608      0.614      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14/60       8.2G      1.564       1.69      1.952         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.683      0.687      0.718      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15/60       8.2G      1.534      1.608      1.922         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.629      0.634      0.663      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16/60      8.24G      1.496      1.579       1.88         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.557      0.633      0.629      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17/60      8.24G      1.461       1.55      1.866         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.717      0.631      0.696      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18/60       8.3G      1.452      1.531      1.852         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.5s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.724      0.639      0.716      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19/60       8.3G      1.424      1.453       1.83         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.788      0.721       0.79      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20/60       8.3G      1.427      1.444       1.82         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.825      0.671      0.769      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      21/60       8.3G      1.396      1.413       1.81         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.741      0.702      0.765      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      22/60       8.3G      1.367      1.382      1.772         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.754      0.668      0.757      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      23/60       8.3G      1.355      1.345       1.77         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 6.3it/s 0.8s\n",
      "                   all        132        271      0.792      0.665      0.748      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      24/60       8.3G      1.339      1.319      1.749         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.813      0.764      0.839      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      25/60       8.3G      1.316      1.309      1.731         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.718      0.767      0.832      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      26/60       8.3G      1.319      1.305      1.727         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.785      0.734      0.811       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      27/60       8.3G      1.295      1.241      1.702         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.733      0.761      0.786      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      28/60       8.3G       1.29      1.238      1.701         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.812      0.762      0.822      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      29/60       8.3G      1.272      1.207      1.679         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.821      0.762      0.848       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      30/60       8.3G      1.265      1.205      1.677         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.798      0.723      0.825      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      31/60       8.3G      1.238      1.172      1.661         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.765      0.784      0.841      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      32/60       8.3G      1.223      1.155      1.662         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.2it/s 0.7s\n",
      "                   all        132        271      0.851      0.773      0.862      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      33/60       8.3G      1.212      1.136       1.65         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.3s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.853       0.76      0.863      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      34/60       8.3G      1.191      1.122      1.628         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271       0.79      0.763      0.847      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      35/60       8.3G      1.186      1.075      1.613         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.821      0.839      0.868      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      36/60       8.3G      1.177      1.082      1.614         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.839      0.793      0.878      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      37/60       8.3G      1.158      1.053      1.605         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.789      0.791      0.858      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      38/60       8.3G      1.129       1.01       1.57         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.1it/s 0.7s\n",
      "                   all        132        271      0.799      0.801      0.852      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      39/60       8.3G      1.144      1.029      1.589         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.893      0.802      0.895       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      40/60       8.3G      1.139      1.016      1.583         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.859      0.784      0.868      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      41/60       8.3G      1.123       1.01      1.558         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.894       0.82      0.908      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      42/60       8.3G      1.111      0.985      1.563         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.879      0.816        0.9      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      43/60       8.3G      1.107     0.9905      1.557         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.3s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.901      0.818        0.9      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      44/60       8.3G      1.096     0.9523      1.545         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.903      0.812      0.908       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      45/60       8.3G      1.065     0.9503      1.528         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.873      0.833      0.901      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      46/60       8.3G      1.062     0.9268       1.52         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.883      0.835       0.92      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      47/60       8.3G      1.052       0.91       1.51         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.891      0.853      0.921       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      48/60       8.3G      1.063     0.9065      1.521         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.919      0.786      0.913      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      49/60       8.3G       1.03     0.8883      1.489         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.824      0.835      0.906      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      50/60       8.3G      1.039     0.8921      1.507         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.2s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.929      0.839      0.921       0.65\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      51/60       8.3G      0.878     0.6697      1.347         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.3s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271       0.87      0.816      0.905      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      52/60       8.3G     0.8551     0.6208      1.347         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.3it/s 16.4s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.857      0.845      0.914      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      53/60       8.3G      0.837     0.5853      1.321         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 6.6it/s 0.8s\n",
      "                   all        132        271      0.892      0.845      0.919       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      54/60       8.3G     0.8329     0.5926      1.316         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.914      0.848      0.923      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      55/60       8.3G     0.8272     0.5708      1.307         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.912      0.842      0.927      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      56/60       8.3G     0.7974     0.5521      1.287         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.896      0.851      0.927      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      57/60       8.3G      0.802     0.5568      1.287         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.918      0.837      0.924      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      58/60       8.3G     0.8047     0.5619      1.291         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.892      0.856      0.926      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      59/60       8.3G     0.8118     0.5737      1.311         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.895      0.846      0.922      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      60/60       8.3G     0.7951     0.5565      1.294          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 87/87 5.4it/s 16.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 7.3it/s 0.7s\n",
      "                   all        132        271      0.904      0.842      0.925      0.666\n",
      "\n",
      "60 epochs completed in 0.301 hours.\n",
      "Optimizer stripped from /workspace/runs/detect/tank_yolo_cbam_640_final/weights/last.pt, 52.2MB\n",
      "Optimizer stripped from /workspace/runs/detect/tank_yolo_cbam_640_final/weights/best.pt, 52.2MB\n",
      "\n",
      "Validating /workspace/runs/detect/tank_yolo_cbam_640_final/weights/best.pt...\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45498MiB)\n",
      "YOLOv8m_cbam_real_final summary (fused): 116 layers, 25,906,303 parameters, 0 gradients, 78.8 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.8it/s 1.0s\n",
      "                   all        132        271      0.892      0.856      0.926      0.667\n",
      "                   APC         35         39      0.803      0.923      0.925      0.744\n",
      "                  Tank         64         84      0.944      0.807      0.937       0.71\n",
      "                person         58        148      0.928      0.838      0.916      0.546\n",
      "Speed: 0.1ms preprocess, 3.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/runs/detect/tank_yolo_cbam_640_final\u001b[0m\n",
      "âœ… í•™ìŠµ ì¢…ë£Œ | tank_yolo_cbam_640_final\n",
      "\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ | imgsz=800, batch=8, epochs=50, cache=False, run=tank_yolo_cbam_800_final\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      "Transferred 135/484 items from pretrained weights\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45498MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/detection-base-6/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=800, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m_cbam_real_final.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=tank_yolo_cbam_800_final, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8m.pt, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspace/runs/detect/tank_yolo_cbam_800_final, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "  5                  -1  1      4706  CBAM_Universal                               [192]                         \n",
      "  6                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  7                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "  8                  -1  1     18530  CBAM_Universal                               [384]                         \n",
      "  9                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      " 10                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      " 11                  -1  1     41570  CBAM_Universal                               [576]                         \n",
      " 12                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 5]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 19                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 22                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 23            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 25        [18, 21, 24]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
      "YOLOv8m_cbam_real_final summary: 193 layers, 25,922,863 parameters, 25,922,847 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 484/484 items from pretrained weights\n",
      "Freezing layer 'model.25.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 18.6Â±3.0 MB/s, size: 61.1 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/detection-base-6/train/labels.cache... 1384 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1384/1384 86.6Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.2 ms, read: 20.4Â±4.6 MB/s, size: 47.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/detection-base-6/valid/labels.cache... 132 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 132/132 2.0Mit/s 0.0s\n",
      "Plotting labels to /workspace/runs/detect/tank_yolo_cbam_800_final/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 93 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 800 train, 800 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/runs/detect/tank_yolo_cbam_800_final\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1/50      5.62G      3.055      3.466      3.428         22        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.0it/s 29.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 7.3it/s 1.2s\n",
      "                   all        132        271       0.72     0.0556     0.0431     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2/50      6.49G      2.466      2.807      2.909         21        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.8it/s 1.0s\n",
      "                   all        132        271      0.124      0.323      0.119     0.0442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       3/50      6.54G      2.196      2.561      2.652         35        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.0it/s 1.0s\n",
      "                   all        132        271      0.292      0.304      0.226     0.0863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       4/50      6.54G      2.029      2.439      2.479         34        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.0it/s 1.0s\n",
      "                   all        132        271      0.262      0.421      0.293      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5/50      6.54G      1.943      2.324      2.408         25        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
      "                   all        132        271      0.338      0.409      0.288      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6/50      6.54G      1.872      2.229      2.334         15        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
      "                   all        132        271      0.319      0.429      0.339      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       7/50      6.54G      1.809      2.147       2.26         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271       0.33      0.469       0.33      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8/50       6.6G       1.78       2.15      2.245         18        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.3it/s 1.1s\n",
      "                   all        132        271      0.532      0.512       0.44      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       9/50       6.6G      1.746      2.076      2.185         21        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
      "                   all        132        271      0.476      0.506      0.454      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10/50      6.61G      1.692      1.989      2.152         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.469      0.584      0.487      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11/50      6.67G      1.682      1.928      2.123         25        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.522      0.582      0.489      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12/50      6.74G      1.625      1.875      2.082         41        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.496      0.562      0.529      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13/50      6.74G      1.607       1.85      2.056         44        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.574      0.638      0.614      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14/50      6.74G       1.57      1.793      2.041         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.684       0.59      0.638      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15/50      6.76G      1.557      1.742      2.004         24        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271       0.55      0.585      0.588      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16/50      6.76G      1.561      1.739      2.006         29        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271       0.65      0.696      0.693      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17/50      6.76G      1.512      1.691      1.981         36        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.638      0.622      0.634      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18/50      6.76G      1.487       1.62      1.947         21        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.694      0.628      0.645      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19/50      6.76G       1.47      1.556      1.917         28        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.726      0.681       0.74      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20/50      6.76G      1.474      1.605      1.927         33        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.791      0.657      0.756      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      21/50      6.76G      1.441      1.545      1.909         44        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.3it/s 1.1s\n",
      "                   all        132        271      0.697      0.693      0.731      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      22/50      6.76G      1.416      1.509      1.874         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.745      0.723      0.794        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      23/50      6.76G      1.379      1.446      1.841         28        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.784      0.798      0.815      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      24/50       6.8G      1.394      1.438      1.855         29        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.768       0.67      0.779      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      25/50       6.8G      1.345      1.392      1.815         19        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.837      0.741      0.817      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      26/50       6.8G      1.372      1.402       1.83         23        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.757       0.76      0.807       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      27/50       6.8G      1.342      1.368        1.8         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.845      0.717       0.83      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      28/50       6.8G      1.306      1.351      1.793         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.887      0.712      0.839      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      29/50       6.8G      1.305      1.338      1.778         29        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.819      0.767      0.852      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      30/50       6.8G      1.278      1.282       1.75         24        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.825      0.797      0.858       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      31/50       6.8G      1.272      1.268      1.746         30        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.866      0.768      0.863      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      32/50       6.8G      1.238      1.229      1.726         15        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.876      0.787      0.864      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      33/50      7.18G      1.239      1.227      1.728         24        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.856      0.794      0.857      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      34/50      7.18G      1.209      1.166      1.691         15        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.4it/s 1.1s\n",
      "                   all        132        271      0.859      0.789      0.864      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      35/50      7.18G        1.2      1.154      1.688         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.5it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271       0.86      0.811      0.878      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      36/50      7.18G       1.21      1.135      1.684         26        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.885       0.79      0.888      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      37/50      7.18G      1.147      1.109      1.658         33        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.908      0.805      0.904      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      38/50      7.18G      1.158      1.122      1.653         33        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
      "                   all        132        271      0.879      0.797      0.887      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      39/50      7.18G       1.15      1.093      1.652         26        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.883      0.801      0.886      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      40/50      7.18G      1.151      1.073      1.635         28        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.871      0.832      0.899      0.618\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      41/50      7.18G      1.001     0.8201      1.556         15        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1it/s 1.0s\n",
      "                   all        132        271      0.891      0.833      0.893      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      42/50      7.18G      0.981     0.7748      1.545          8        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.1s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.904       0.82      0.903      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      43/50      7.18G     0.9505     0.7281      1.515          9        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.897      0.843      0.902      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      44/50      7.18G     0.9367     0.7224      1.502         15        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.5it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.903       0.83      0.906       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      45/50      7.18G       0.92     0.7118      1.503         16        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.9s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.906      0.833      0.909      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      46/50      7.18G     0.9081     0.7024      1.481         27        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 27.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271       0.92      0.828      0.906      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      47/50      7.18G     0.9156     0.6833      1.486         14        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.5it/s 26.7s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.9it/s 1.0s\n",
      "                   all        132        271      0.908      0.834      0.899      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      48/50      7.18G     0.8926     0.6797      1.463          9        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.5it/s 26.7s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.912      0.833      0.905      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      49/50      7.18G     0.8949     0.6716      1.472          9        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.3it/s 1.0s\n",
      "                   all        132        271      0.897      0.829      0.903      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      50/50      7.18G      0.879      0.676      1.455         14        800: 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 6.4it/s 26.8s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.2it/s 1.0s\n",
      "                   all        132        271      0.907      0.815        0.9      0.629\n",
      "\n",
      "50 epochs completed in 0.405 hours.\n",
      "Optimizer stripped from /workspace/runs/detect/tank_yolo_cbam_800_final/weights/last.pt, 52.2MB\n",
      "Optimizer stripped from /workspace/runs/detect/tank_yolo_cbam_800_final/weights/best.pt, 52.2MB\n",
      "\n",
      "Validating /workspace/runs/detect/tank_yolo_cbam_800_final/weights/best.pt...\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45498MiB)\n",
      "YOLOv8m_cbam_real_final summary (fused): 116 layers, 25,906,303 parameters, 0 gradients, 78.8 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 6.4it/s 1.4s\n",
      "                   all        132        271      0.907      0.834      0.899      0.634\n",
      "                   APC         35         39      0.897      0.892      0.909      0.733\n",
      "                  Tank         64         84      0.929      0.845      0.936      0.674\n",
      "                person         58        148      0.895      0.764      0.852      0.496\n",
      "Speed: 0.2ms preprocess, 4.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/runs/detect/tank_yolo_cbam_800_final\u001b[0m\n",
      "âœ… í•™ìŠµ ì¢…ë£Œ | tank_yolo_cbam_800_final\n",
      "\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ | imgsz=1280, batch=4, epochs=50, cache=False, run=tank_yolo_cbam_1280_final\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      "Transferred 135/484 items from pretrained weights\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45498MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/workspace/detection-base-6/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m_cbam_real_final.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=tank_yolo_cbam_1280_final, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8m.pt, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspace/runs/detect/tank_yolo_cbam_1280_final, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 192\n",
      "  5                  -1  1      4706  CBAM_Universal                               [192]                         \n",
      "  6                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  7                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 384\n",
      "  8                  -1  1     18530  CBAM_Universal                               [384]                         \n",
      "  9                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      " 10                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "âœ… CBAM ìƒì„±ë¨ | ì ìš© ì±„ë„: 576\n",
      " 11                  -1  1     41570  CBAM_Universal                               [576]                         \n",
      " 12                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 5]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 19                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 22                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 23            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 25        [18, 21, 24]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
      "YOLOv8m_cbam_real_final summary: 193 layers, 25,922,863 parameters, 25,922,847 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 484/484 items from pretrained weights\n",
      "Freezing layer 'model.25.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 48.2Â±10.6 MB/s, size: 61.1 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/detection-base-6/train/labels.cache... 1384 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1384/1384 89.3Mit/s 0.0s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.0 ms, read: 21.9Â±16.2 MB/s, size: 47.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/detection-base-6/valid/labels.cache... 132 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 132/132 1.6Mit/s 0.0s\n",
      "Plotting labels to /workspace/runs/detect/tank_yolo_cbam_1280_final/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 93 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/runs/detect/tank_yolo_cbam_1280_final\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1/50      6.76G      3.119      3.838      3.624         17       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.1it/s 1:08\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.3it/s 2.3s\n",
      "                   all        132        271      0.689     0.0317     0.0229     0.0095\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2/50      7.84G      2.601      3.302      3.164          6       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:06\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.4it/s 2.3s\n",
      "                   all        132        271      0.121      0.205     0.0877     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       3/50      7.84G      2.374       3.14      2.956         14       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.3it/s 2.3s\n",
      "                   all        132        271      0.164       0.24      0.125     0.0379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       4/50      7.84G      2.263      3.011      2.805         17       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.6it/s 2.2s\n",
      "                   all        132        271      0.199      0.187      0.153     0.0466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       5/50      7.84G      2.196      2.897      2.755         17       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:06\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.9it/s 2.2s\n",
      "                   all        132        271      0.172      0.366      0.237      0.094\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6/50      7.84G      2.101      2.777      2.661         12       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.9it/s 2.2s\n",
      "                   all        132        271      0.317       0.28      0.238      0.098\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       7/50      7.89G      2.026      2.654      2.622         13       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 7.9it/s 2.2s\n",
      "                   all        132        271      0.337      0.361      0.275      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8/50      7.96G      1.977      2.602       2.58         13       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 346/346 5.3it/s 1:05\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 8.0it/s 2.1s\n",
      "                   all        132        271      0.363      0.375       0.31      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:93.)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# 6. ë©€í‹° ìŠ¤í…Œì´ì§€ í•™ìŠµ ì‹¤í–‰\n",
    "#    - 640: ìƒëŒ€ì ìœ¼ë¡œ ì—¬ìœ  â†’ cache ì‚¬ìš© ê°€ëŠ¥ (ì›í•˜ë©´ True)\n",
    "#    - 800 / 1280: ë©”ëª¨ë¦¬ ê³ ë ¤í•´ì„œ cache=False ê¶Œì¥\n",
    "# ======================================================================================\n",
    "'''\n",
    "# Step 1: 640\n",
    "train_stage(\n",
    "    yaml_path=yaml_name,\n",
    "    data_yaml=data_path,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    epochs=60,\n",
    "    patience=50,\n",
    "    run_name=\"tank_yolo_cbam_640_final\",\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    cache=True,   # ì—¬ê¸°ëŠ” ìƒí™© ë´ì„œ True/False ì¡°ì •\n",
    ")\n",
    "'''\n",
    "\n",
    "# Step 2: 800\n",
    "train_stage(\n",
    "    yaml_path=yaml_name,\n",
    "    data_yaml=data_path,\n",
    "    imgsz=800,\n",
    "    batch=8,\n",
    "    epochs=100,\n",
    "    patience=30,\n",
    "    run_name=\"tank_yolo_cbam_800_final\",\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    cache=False,  # 800ë¶€í„°ëŠ” ë©”ëª¨ë¦¬ í„°ì§ˆ ìˆ˜ ìˆì–´ì„œ False ì¶”ì²œ\n",
    ")\n",
    "\n",
    "'''# Step 3: 1280\n",
    "train_stage(\n",
    "    yaml_path=yaml_name,\n",
    "    data_yaml=data_path,\n",
    "    imgsz=1280,\n",
    "    batch=4,\n",
    "    epochs=50,\n",
    "    patience=30,\n",
    "    run_name=\"tank_yolo_cbam_1280_final\",\n",
    "    device=0,\n",
    "    workers=4,\n",
    "    cache=False,  # 1280ì€ ë¬´ì¡°ê±´ False\n",
    ")\n",
    "'''\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ìŠ¤í…Œì´ì§€ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7632268-1abe-4618-984d-f04cd8ba37bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
